{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8a2290",
   "metadata": {},
   "source": [
    "# Cart Pole Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051d2ae",
   "metadata": {},
   "source": [
    "Cart Pole is an environment provided by OpenAI gym. This is a really basic Reinforcement Learning (RL) environment - I recently saw it described as the \"Hello World\" of RL. The environment considers a pole on a cart, and the cart can either move left or right in order to keep the pole upright. If the pole falls beyond a certain angle, or the cart moves outside certain bounds, the episode terminates. \n",
    "\n",
    "The state is defined by the observation - this has cart position, cart velocity, pole angle, and pole\n",
    "angular velocity in that order (these numbers are the output from env.reset()). env.step(action = 0 or 1) gives us observation, reward, done, info, in that order. The reward is +1 for every additional step, including the termination step. More information on the environment can be found here: https://www.gymlibrary.dev/environments/classic_control/cart_pole/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0cf8e4",
   "metadata": {},
   "source": [
    "In this notebook, I want to build and train a RL agent to solve this environment successfully using a DDQN algorithm. I plan on experimenting with the following variables:\n",
    "- Neural net architectures\n",
    "- Learning rates \n",
    "- Epsilon values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cf4f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from IPython import display\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82846799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \"\"\"\n",
    "    RL agent that utilizes a DQN algorithm to solve the Cart Pole environment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=0.95, epsilon=0.9, epsilon_decay=0.99, epsilon_min=0.01, tau=0.99):\n",
    "        \"\"\"\n",
    "        Initialize agent.\n",
    "        \n",
    "        Arguments:\n",
    "            gamma (float): Future reward discounting factor\n",
    "            epsilon (float): Starting value representing percentage of the time that the agent chooses a random action. E.g 0.75 = 75%\n",
    "            epsilon_decay (float): Epsilon is multiplied by this factor after each episode.\n",
    "            epsilon_min (float): Minimum value for epsilon.\n",
    "            tau (float): Rate at which the target-q network is updated.\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min \n",
    "        self.tau = tau\n",
    "        self.q_function = self.make_q_function()\n",
    "        self.q_function.compile(loss='mse', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)) \n",
    "        self.target_q = self.make_q_function()\n",
    "        self.target_q.compile(loss='mse', optimizer='adam')\n",
    "        self.target_q.set_weights(self.q_function.weights)\n",
    "        self.max_memory = 10000\n",
    "    \n",
    "    \n",
    "    def find_action(self, state):\n",
    "        \"\"\"\n",
    "        Taking an action according to current policy of the agent. \n",
    "        \n",
    "        Arguments:\n",
    "            state (ndarray): cart position, cart velocity, pole angle, and pole angular velocity\n",
    "        \n",
    "        Returns:\n",
    "            action (int): 0 or 1, corresponding to whether to push the cart left or right.\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the random number is less than epsilon, we choose the action randomly\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(0, 2)\n",
    "            \n",
    "        # Otherwise, choose the action that is the agent's current best guess for max future reward\n",
    "        else:\n",
    "            # Find action with best q-value\n",
    "            # Find q-value estimates for each action using q-function\n",
    "            q_vals = self.q_function.predict(state[np.newaxis, :], verbose=False)\n",
    "            # Find best value by taking index of the largest argument\n",
    "            action = np.argmax(q_vals)\n",
    "    \n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def take_step(self, env):\n",
    "        \"\"\"\n",
    "        Take a step in the Cart Pole environment with the agent.\n",
    "        \n",
    "        Arguments:\n",
    "            env: Cart Pole environment object\n",
    "        \n",
    "        Returns:\n",
    "            old_state (ndarray): initial cart position, cart velocity, pole angle, and pole angular velocity\n",
    "            action (int): 0 or 1, corresponding to whether the cart was pushed left or right\n",
    "            reward (int): +1 if the episode has not yet terminated, 0 otherwise\n",
    "            new_state (ndarray): new cart position, cart velocity, pole angle, and pole angular velocity\n",
    "            done (bool): Whether or not episode has terminated\n",
    "        \"\"\"\n",
    "        \n",
    "        # Find action\n",
    "        action = self.find_action(self.state)\n",
    "        \n",
    "        # Take step\n",
    "        new_state, reward, done, info = env.step(action)[:4]\n",
    "        old_state = self.state\n",
    "        self.state = new_state\n",
    "        \n",
    "        return old_state, action, reward, new_state, done\n",
    "    \n",
    "    \n",
    "    def make_q_function(self):\n",
    "        \"\"\"\n",
    "        Create a q-function to estimate optimal total reward values for a given state-action pair.\n",
    "        \n",
    "        Arguments:\n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            model: Untrained Keras sequential model. \n",
    "        \"\"\"\n",
    "        \n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(128, activation='relu', input_shape=(4,)),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dense(2, activation='linear')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Use memory of experience to train agent using gradient descent.\n",
    "        \n",
    "        Arguments:\n",
    "            None\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "            \n",
    "        # Define target = current reward + gamma * target q of next state\n",
    "        \n",
    "        # Target q network predictions of future reward\n",
    "        future_reward = np.max(self.target_q.predict(self.memory[:, -4:], verbose=False), axis=1)\n",
    "        # Accounting for steps where episode terminated (no future reward)\n",
    "        future_reward = np.where(self.memory[:, 6], 0, future_reward)\n",
    "        \n",
    "        target_vals = self.memory[:, 5] + self.gamma * future_reward\n",
    "        \n",
    "        # Creating targets\n",
    "        q_vals = self.q_function.predict(self.memory[:, :4], verbose=False)\n",
    "        \n",
    "        current_actions = self.memory[:, 4]\n",
    "        # Replacing predictions with targets\n",
    "        col1 = ((q_vals[:, 0] * current_actions) + ((1 - current_actions) * target_vals)).reshape(q_vals.shape[0], 1)\n",
    "        col2 = ((q_vals[:, 1] * (1 - current_actions)) + (current_actions * target_vals)).reshape(q_vals.shape[0], 1)\n",
    "        final_target = np.concatenate((col1, col2), axis=1)\n",
    "        \n",
    "        # Train q-function with mse against target-q\n",
    "        self.q_function.fit(self.memory[:, :4], final_target, shuffle=True, batch_size=64, verbose=False)\n",
    "        \n",
    "        # Using Polyak averaging to soft update target-q to be tau * target q weights + (1 - tau) * q weights\n",
    "        new_weights = [self.tau * i + (1 - self.tau) * j for i, j in zip(self.target_q.weights, self.q_function.weights)]\n",
    "        self.target_q.set_weights(new_weights) \n",
    "        \n",
    "        \n",
    "    def go(self, env, num_rounds=100):\n",
    "        \"\"\"\n",
    "        Run the agent till termination num_rounds times.\n",
    "        \n",
    "        Arguments:\n",
    "            env: Cart Pole environment object\n",
    "            num_rounds (int): Number of times we want the agent to run until termination.\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initializing memory and episode length record\n",
    "        self.memory = np.zeros((1, 11))\n",
    "        length_lst = []\n",
    "        \n",
    "        # Each round is a complete runthrough of the environment until termination\n",
    "        for i in tqdm(range(num_rounds)):\n",
    "            \n",
    "            # Tracking whether or not current iteration has terminated\n",
    "            complete = False\n",
    "            \n",
    "            # Resetting to initial state\n",
    "            self.state = env.reset()[0]\n",
    "            \n",
    "            # Variable to keep track of number of steps taken in each round\n",
    "            length = 0\n",
    "            \n",
    "            while not complete:\n",
    "                \n",
    "                # Continue taking steps until termination\n",
    "                old_state, action, reward, new_state, done = self.take_step(env)\n",
    "                \n",
    "                # Add data to agent memory\n",
    "                if self.memory.any():\n",
    "                    curr_data = np.append(np.append(old_state, (action, reward, done)), new_state).reshape(1, 11)\n",
    "                    self.memory = np.concatenate((self.memory, curr_data), axis=0)\n",
    "                else: \n",
    "                    self.memory = (np.append(np.append(old_state, (action, reward, done)), new_state)).reshape(1, 11)\n",
    "                \n",
    "                # Sample memory if exceeding memory limit\n",
    "                # Always keep initial 1000 steps' data\n",
    "                if len(self.memory) > self.max_memory:\n",
    "                    idx = np.random.randint(1000, self.max_memory, size=self.max_memory - 1000) \n",
    "                    self.memory = self.memory[np.append(np.arange(1000), idx), :]\n",
    "                \n",
    "                # Need > 64 for batch size\n",
    "                if len(self.memory) > 64:\n",
    "                    self.train()\n",
    "                \n",
    "                if done:\n",
    "                    complete = True\n",
    "                    \n",
    "                length += 1\n",
    "                \n",
    "                if length > 550:\n",
    "                    break\n",
    "\n",
    "                \n",
    "             # Decrease epsilon\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            self.epsilon = max(self.epsilon, self.epsilon_min)\n",
    "            \n",
    "            length_lst.append(length)\n",
    "            \n",
    "            if np.mean(length_lst[-10:]) >= 475:\n",
    "                break\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(\"Episode {} last 10 reward avg: {}, epsilon: {}\".format(i, np.mean(length_lst[-10:]), self.epsilon))\n",
    "                               \n",
    "        return length_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc9eccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(lengths, window):\n",
    "    \"\"\"\n",
    "    Find the rolling average of the episode length.\n",
    "    \n",
    "    Arguments:\n",
    "        lengths (lst): List of episode lengths\n",
    "        window (int): Length of rolling average window of consideration\n",
    "        \n",
    "    Returns:\n",
    "        avgs (lst):\n",
    "    \"\"\"\n",
    "    avgs = []\n",
    "    for i in range(len(lengths)):\n",
    "        if i < window:\n",
    "            avgs.append(0)\n",
    "        else:\n",
    "            avgs.append(np.mean(lengths[i - window: i]))\n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb100541",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d41628ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdbcef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                    | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 last 10 reward avg: 18.0, epsilon: 0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                          | 11/1000 [00:12<22:07,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 last 10 reward avg: 21.9, epsilon: 0.8058044288328449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                         | 21/1000 [00:29<33:40,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20 last 10 reward avg: 20.1, epsilon: 0.7287550813991327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                      | 31/1000 [01:00<1:03:04,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30 last 10 reward avg: 34.5, epsilon: 0.6590730326889578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                       | 41/1000 [01:24<53:25,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40 last 10 reward avg: 24.9, epsilon: 0.5960538368855853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                      | 51/1000 [01:54<47:56,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 last 10 reward avg: 28.2, epsilon: 0.5390604058195451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▍                                                                                   | 61/1000 [02:40<1:29:54,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60 last 10 reward avg: 37.8, epsilon: 0.48751656837016827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▎                                                                                  | 71/1000 [03:16<1:13:47,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 70 last 10 reward avg: 27.9, epsilon: 0.4409012457037845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▏                                                                                 | 81/1000 [04:00<1:01:08,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 80 last 10 reward avg: 30.5, epsilon: 0.39874318346355536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████                                                                                 | 91/1000 [05:15<2:17:05,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 90 last 10 reward avg: 48.7, epsilon: 0.3606161876563865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▉                                                                               | 101/1000 [06:27<1:23:08,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 last 10 reward avg: 42.2, epsilon: 0.3261348160744472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▊                                                                              | 111/1000 [08:30<2:13:26,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 110 last 10 reward avg: 65.9, epsilon: 0.2949504816940234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▋                                                                             | 121/1000 [11:27<4:52:36, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 120 last 10 reward avg: 83.7, epsilon: 0.26674792865928726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▌                                                                            | 131/1000 [14:11<5:23:32, 22.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 130 last 10 reward avg: 69.3, epsilon: 0.24124204522518672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▉                                                                            | 136/1000 [16:18<5:25:34, 22.61s/it]"
     ]
    }
   ],
   "source": [
    "lengths = agent.go(env, num_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = np.arange(1000)\n",
    "plt.plot(iters, rolling_average(lengths, 10))\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Episode length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "agent.state = env.reset()[0]\n",
    "agent_lengths = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    \n",
    "    env.reset()\n",
    "    \n",
    "    ep_length = 0\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        _, _, _, _, done = agent.take_step(env)\n",
    "        ep_length += 1\n",
    "    \n",
    "    agent_lengths.append(ep_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "random_lengths = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    \n",
    "    env.reset()\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    ep_length = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = np.random.randint(0, 2)\n",
    "        _, _, done, _, _ = env.step(action)\n",
    "        ep_length += 1\n",
    "    \n",
    "    random_lengths.append(ep_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f328bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(agent_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401daf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(random_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(100), rolling_average(agent_lengths, 10), label='Agent')\n",
    "plt.plot(np.arange(100), rolling_average(random_lengths, 10 ), label='Random')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdb8369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "agent.state = env.reset()[0]\n",
    "\n",
    "for i in range(50):\n",
    "    plt.imshow(env.render())\n",
    "    display.display(plt.gcf())    \n",
    "    display.clear_output(wait=True)\n",
    "#     env.step(env.action_space.sample()) # take a random action\n",
    "    env.step(agent.find_action(agent.state))\n",
    "    agent.state = np.array(env.state)\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab8f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
